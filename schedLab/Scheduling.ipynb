{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE 424 Scheduling Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import expovariate\n",
    "%matplotlib inline\n",
    "\n",
    "import doctest\n",
    "def test(fun, verbose=False):\n",
    "    doctest.run_docstring_examples(fun, None, name=fun.__name__, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Model\n",
    "\n",
    "Our model of a task ignores what computation and I/O it actually does; we are only interested in its scheduling events.  This is captured by three basic parameters, all of which operate in an abstract time unit, say ms:\n",
    "\n",
    "* arrival - the time at which the task is first initiated\n",
    "* total - total execution time of the task (how long it runs).  Generally we don't know this value, although to simulate oracle scheduling we could peek.  It determines when the task exits.\n",
    "* burst_fun - a function that returns the length of the next CPU burst, given its elapsed execution time.  This can be viewed as the time to the next syscall.  A value of 0 is taken to be run-to-completion.  A periodic application simply returns a constant, the number of time units in each burst duration.  A stochastic model is obtained by drawing a value according to some distribution.\n",
    "* io_burst_fun - a function that returns the length of time the task spends waiting for I/O etc.\n",
    "\n",
    "\n",
    "\n",
    "The overall workload is described by a stream of such tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task(object):\n",
    "    \"\"\" Model of a program task: \n",
    "    arrives as a certain time and then alternates CPU and IO bursts of possibly varying length\n",
    "    till it has executed for a certain amount of CPU time\n",
    "    \"\"\"\n",
    "    task_number = 0   # Unique identifier for each task\n",
    "    \n",
    "    def __init__(self, arrival, total, burst_fun, io_burst_fun):\n",
    "        \"\"\"Create a task with specified arrival, total run time, and functions modeling burst lengths.\"\"\"\n",
    "        Task.task_number += 1\n",
    "        self.task = Task.task_number\n",
    "        self.arrival_time = arrival\n",
    "        self.total_run_time = total\n",
    "        self.cpu_burst = burst_fun\n",
    "        self.io_burst = io_burst_fun\n",
    "        return None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Task {} arr:{} len:{}\".format(self.task, self.arrival_time, self.total_run_time)\n",
    "\n",
    "class TaskStream(object):\n",
    "    \"\"\"Stream of tasks arriving as time moves forward\"\"\"\n",
    "    def __init__(self, tasks):\n",
    "        self.tasks = sorted(tasks, key=lambda x: x.arrival_time)\n",
    "    \n",
    "    def next_arrival(self):\n",
    "        if not self.tasks:\n",
    "            return None\n",
    "        return self.tasks[0].arrival_time\n",
    "    \n",
    "    def enter_tasks(self, time):\n",
    "        \"\"\"Generate a thread for and remove each tasks arriving upto time. \"\"\"\n",
    "        for task in self.tasks.copy():\n",
    "            if task.arrival_time <= time:\n",
    "                self.tasks.remove(task)\n",
    "                yield Thread(task)\n",
    "\n",
    "    def show(self):\n",
    "        for t in self.tasks:\n",
    "            print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread Model\n",
    "\n",
    "The execution of the steps of a task is emulated by `Thread` class `run` method.  It is passed the length of the CPU quanta up to which may run, with `q == 0` indicating indefinitely, i.e., to the end of its burst or to completion.  Based on its internal bookkeeping, i.e., where the thread is in the current burst and the task time to completion, \n",
    "`run` determines how long the thread will run and returns that value along with a status indicating whether the\n",
    "thread continues to run at the end of the quantum (\"cpu\"), blocked before the quantum (\"io\"), or ran to completion (\"done\"). \n",
    "\n",
    "One subtlety is that if a tasks is scheduled multiple times to complete a burst, the `burst_fun` is not used until the task is rescheduled after the completes, i.e., it would be returning from the syscall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thread(object):\n",
    "    \"\"\" Model of a running process thread.\n",
    "    \n",
    "    Each time a task is run, it executes for 1 or more time units, until it\n",
    "    - completes a cpu burst\n",
    "    - exhausts a quanta (under preemptive scheduling), or\n",
    "    - completes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task):\n",
    "        \"\"\"Create a thread object with characteristics of modeled task.\"\"\"\n",
    "        self.task = task\n",
    "        self.elapsed_time = 0\n",
    "        self.last_queued = None\n",
    "        self.wait_time = 0\n",
    "        self.remaining_burst = None\n",
    "        self.wakeup_time = None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Thread {} | elapsed: {} wait:{} rbrst:{} wakeup: {}\".format(self.task, \n",
    "                                    self.elapsed_time, self.wait_time, self.remaining_burst, self.wakeup_time)\n",
    "        \n",
    "    def remaining(self):\n",
    "        return self.task.total_run_time - self.elapsed_time\n",
    "    \n",
    "    def run(self, q=0):\n",
    "        \"\"\" Advance the thread for up to q units (q==0 is nonpremptive) till cpu burst completes or done\"\"\"\n",
    "        io_time = None\n",
    "        if (self.remaining_burst):  # Still completing burst\n",
    "            if q > 0:                 # preemptive : run for Q, burst done, or pgm done\n",
    "                run_len = min(q, self.remaining_burst, self.remaining())\n",
    "            else:                      # non-preemptive : run till burst or pgm down\n",
    "                run_len = min(self.remaining_burst, self.remaining())\n",
    "            self.remaining_burst -= run_len\n",
    "            self.elapsed_time += run_len\n",
    "            if self.remaining_burst:                    # Still working on prior CPU burst\n",
    "                status = 'cpu'\n",
    "            else:\n",
    "                status = 'io'                            # completed the burst, start wait\n",
    "                io_time = self.task.io_burst(self.elapsed_time) \n",
    "        else:                                                             # starting a new burst\n",
    "            burst = self.task.cpu_burst(self.elapsed_time)   \n",
    "            if burst == 0 and q == 0:                                # run till done\n",
    "                run_len = self.remaining()           \n",
    "            elif burst == 0:                                           # run till Q or done\n",
    "                run_len = min(q, self.remaining())  \n",
    "            elif q == 0:                                               # run till burst or done\n",
    "                run_len = min(burst, self.remaining())\n",
    "            else:                                                         # run till Q, burst, or done\n",
    "                run_len = min(q, burst, self.remaining())\n",
    "\n",
    "            self.elapsed_time += run_len\n",
    "            if burst == 0:\n",
    "                status = 'cpu'\n",
    "            elif run_len < burst:                           # Continue CPU burst\n",
    "                self.remaining_burst = burst - run_len\n",
    "                status = 'cpu'\n",
    "            else:                                          # Completed CPU burst, start I/O wait\n",
    "                status = 'io'\n",
    "                io_time = self.task.io_burst(self.elapsed_time) \n",
    "\n",
    "        if self.remaining() <= 0:             # override status if thread finished\n",
    "            status = 'done'\n",
    "        return run_len, status, io_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor  Model\n",
    "\n",
    "We also have a very simple model of a process.  It moves forward in time, either sitting idle or executing a task.  \n",
    "\n",
    "The one complexity is that if tasks arrive or IO completes while a thread is being run, they need to be entered into the ready queue.  Thus, our processor model needs access to the task stream and the enqueue method of the scheduler for such starts and restarts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine(object):\n",
    "    \"\"\"\n",
    "    Simulate machine.  \n",
    "    Time moves forward, either idling or running - this is the only property of the machine\n",
    "    Along the way, it consumes the list of future tasks, builds a log of its actions,\n",
    "    and records the summary of every thread.\n",
    "    \"\"\"\n",
    "    def __init__(self, task_stream, ready, verbose=False):\n",
    "        self.time = 0   \n",
    "        \n",
    "        self.log = [(0, 'start')]\n",
    "        self.threads = []\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.io = []\n",
    "        self.future = task_stream\n",
    "        self.ready = ready\n",
    "        self._arrivals()\n",
    "        \n",
    "    def pending(self):\n",
    "        return self.future.tasks or self.io\n",
    "    \n",
    "    def next_start(self):\n",
    "        \"\"\"Return time of next start or -1 if none.\"\"\"\n",
    "        next_taskstart = self.future.next_arrival()\n",
    "        if self.io and next_taskstart:\n",
    "            return min(next_taskstart, min([t.wakeup_time for t in self.io]))\n",
    "        elif self.io:\n",
    "            return min([t.wakeup_time for t in self.io])\n",
    "        else:\n",
    "            return next_taskstart\n",
    "        \n",
    "    def io_wait(self, thread, wait_time):\n",
    "        \"\"\" Put thread completed cpu burst with positive wait time in IO queue till wakeup\"\"\"\n",
    "        thread.wakeup_time = self.time + wait_time\n",
    "        self.io.append(thread)\n",
    "        if self.verbose:\n",
    "            print(\"{0}: IO wait for Task {1} for duration {2}\".format(self.time, thread.task.task, wait_time))\n",
    "        self.log.append((self.time, 'io wait', thread.task, wait_time))\n",
    "\n",
    "    def _arrivals(self):\n",
    "        # Collect new tasks that arrived while this was idling or running\n",
    "        for thread in self.future.enter_tasks(self.time):\n",
    "            self.threads.append(thread)\n",
    "            self.ready.arrive(thread, thread.task.arrival_time)\n",
    "            if self.verbose:\n",
    "                print(\"{0}: Arrival of Task {1} (ready queue length = {2})\".format(thread.task.arrival_time, thread.task.task, len(self.ready)))\n",
    "            self.log.append((thread.task.arrival_time, 'arrive', thread.task, len(self.ready)))\n",
    "            \n",
    "        # Collect threads that completed IO\n",
    "        for thread in self.io.copy():\n",
    "            if thread.wakeup_time <= self.time:\n",
    "                self.io.remove(thread)\n",
    "                self.ready.wake(thread, thread.wakeup_time)\n",
    "                if self.verbose:\n",
    "                    print(\"{0}: Wakeup of Task {1} (ready queue length = {2})\".format(thread.wakeup_time, thread.task.task, len(self.ready)))\n",
    "                self.log.append((thread.wakeup_time, 'wakeup', thread.task, len(self.ready)))\n",
    "            \n",
    "    \n",
    "    def idle(self):\n",
    "        \"\"\"\n",
    "        Idle from current time till next task arrival or IO wait completes.  \n",
    "        Enter all tasks that arrive or IO complete during idle period ready queue.\n",
    "        \"\"\"\n",
    "        if self.pending():\n",
    "            idle_time = self.next_start()\n",
    "            if idle_time > 0:\n",
    "                if self.verbose:\n",
    "                    print(\"{0}: Idle for {1}\".format(self.time, idle_time - self.time))\n",
    "                self.log.append((self.time, 'idle', idle_time - self.time))\n",
    "                self.time = idle_time          # Processor moves forward in time\n",
    "                self._arrivals()    \n",
    "    \n",
    "    def run(self, run_time, thread):\n",
    "        \"\"\" Advance machine time for run_time.  \n",
    "        Enter new tasks and IO completes during run into ready queue\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"{0}: Run Task {1} for duration {2} (ready queue length = {3})\".format(self.time, thread.task.task, run_time, len(self.ready)))\n",
    "        self.log.append((self.time, 'run', thread.task, run_time, len(self.ready), self.ready.weight()))\n",
    "        self.time += run_time           # All we do to run is move time forward\n",
    "        self._arrivals()\n",
    "            \n",
    "    def stop(self):\n",
    "        if self.verbose:\n",
    "            print(\"{0}: Stop\".format(self.time))\n",
    "        self.log.append((self.time, 'stop'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Schedulers\n",
    "\n",
    "Each scheduler consists of a loop over the workload and a data structure that implements its policy.  The\n",
    "schedule presents the thread with its quanta to the thread model to determine how long it retains the CPU\n",
    "and the status at the end of that time, i.e. CPU, I/O, Done.  \n",
    "\n",
    "Based on that determination, it allows the machine to advance to that point in time.  Along the way, tasks\n",
    "may arrive or threads may complete their I/O wait, so the machine will invoke methods in the scheduler\n",
    "appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCFS and Round Robin\n",
    "\n",
    "Both are built on a simple FIFO queue, the latter with preemption using fixed quanta.  The enqueue and dequeue operation take a simulated time as which it occurs so that they can update observational data carried in the task structure for analysis and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIFOQueue:\n",
    "    \"\"\" FIFO Queue of tasks to be scheduled \"\"\"\n",
    "    def __init__(self):\n",
    "        self.queue = deque()\n",
    "    \n",
    "    def enqueue(self, thread, at_time):\n",
    "        thread.last_queued = at_time\n",
    "        self.queue.appendleft(thread)\n",
    "        \n",
    "    def dequeue(self, at_time):\n",
    "        thread = self.queue.pop()\n",
    "        thread.wait_time += at_time - thread.last_queued\n",
    "        return thread\n",
    "    \n",
    "    def arrive(self, thread, at_time):\n",
    "        self.enqueue(thread, at_time)\n",
    "    \n",
    "    def wake(self, thread, at_time):\n",
    "        self.enqueue(thread, at_time)\n",
    "    \n",
    "    def empty(self):\n",
    "        return len(self.queue) == 0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.queue)\n",
    "    \n",
    "    def weight(self):\n",
    "        return sum([x.task.total_run_time - x.elapsed_time for x in self.queue])\n",
    "    \n",
    "    def show(self):\n",
    "        for e in self.queue:\n",
    "            print(\" \", e)\n",
    "            \n",
    "def scheduler(tasks, q, queue_class, verbose=False):\n",
    "    remaining = TaskStream(tasks)\n",
    "    ready = queue_class()\n",
    "    cpu = Machine(remaining, ready, verbose)\n",
    "\n",
    "    while not ready.empty() or cpu.next_start():\n",
    "        if ready.empty():\n",
    "            cpu.idle()\n",
    "        else:     \n",
    "            thread = ready.dequeue(cpu.time)\n",
    "            run_time, status, io_time = thread.run(q)\n",
    "            cpu.run(run_time, thread)\n",
    "            if status == 'io' and io_time > 0:\n",
    "                cpu.io_wait(thread, io_time)\n",
    "            elif status != 'done':\n",
    "                ready.enqueue(thread, cpu.time)    \n",
    "    cpu.stop()\n",
    "    return cpu\n",
    "    \n",
    "def round_robin(tasks, q, verbose=False):\n",
    "    return scheduler(tasks, q, FIFOQueue, verbose)\n",
    "    \n",
    "def fcfs(tasks, verbose=False):\n",
    "    return round_robin(tasks, 0, verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Burst Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burst functions and factories\n",
    "\n",
    "def indefinite(run_time):\n",
    "    \"\"\"Run till done\"\"\"\n",
    "    return 0;\n",
    "\n",
    "def nowait(run_time):\n",
    "    \"\"\"No I/O wait.\"\"\"\n",
    "    return 0;\n",
    "\n",
    "def make_periodic(duration):\n",
    "    \"\"\"Bursts of constant duration for run or io, i.e., periodic.\"\"\"\n",
    "    return lambda rt: duration\n",
    "\n",
    "def make_exponential(mean_duration):\n",
    "    \"\"\"Bursts of duration drawn from an exponential distribution of specified mean.\"\"\"\n",
    "    return lambda rt: round(expovariate(1.0/mean_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(thrds):\n",
    "    \"\"\"For now just print it out\"\"\"\n",
    "    print(\"---\")\n",
    "    for t in thrds:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Task.task_number = 0\n",
    "\n",
    "workload1 = [\n",
    "    Task(0, 4, indefinite, nowait),\n",
    "    Task(1, 7, indefinite, nowait),\n",
    "    Task(2, 2, make_periodic(1), make_periodic(4)),     # run 1, IO 4, run 1\n",
    "    Task(3, 3, make_periodic(1), make_periodic(1))      # run 1, IO 1, run 1, IO 1, run 1\n",
    "]\n",
    "\n",
    "# Idle two short, 1 long, four short\n",
    "workload2 = [\n",
    "    Task(10,  30, indefinite, nowait),\n",
    "    Task(20,  30, indefinite, nowait),\n",
    "    Task(30, 100, indefinite, nowait),\n",
    "    Task(40,  30, indefinite, nowait),\n",
    "    Task(60,  30, indefinite, nowait),\n",
    "    Task(80,  30, indefinite, nowait),\n",
    "    Task(100,  30, indefinite, nowait)\n",
    "]\n",
    "\n",
    "workload3 = [\n",
    "    Task(0, 4, make_periodic(2), make_periodic(1)),     # run 2, IO 1, run 2\n",
    "    Task(1, 7, indefinite, nowait),\n",
    "    Task(2, 2, make_periodic(1), make_periodic(2)),     # run 1, IO 2, run 1\n",
    "    Task(3, 3, make_periodic(6), make_periodic(1))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fcfs_workload1():\n",
    "    \"\"\" Test FCFS on workload1\n",
    "    \n",
    "    >>> _ = fcfs(workload1, True)\n",
    "    0: Arrival of Task 1 (ready queue length = 1)\n",
    "    0: Run Task 1 for duration 4 (ready queue length = 0)\n",
    "    1: Arrival of Task 2 (ready queue length = 1)\n",
    "    2: Arrival of Task 3 (ready queue length = 2)\n",
    "    3: Arrival of Task 4 (ready queue length = 3)\n",
    "    4: Run Task 2 for duration 7 (ready queue length = 2)\n",
    "    11: Run Task 3 for duration 1 (ready queue length = 1)\n",
    "    12: IO wait for Task 3 for duration 4\n",
    "    12: Run Task 4 for duration 1 (ready queue length = 0)\n",
    "    13: IO wait for Task 4 for duration 1\n",
    "    13: Idle for 1\n",
    "    14: Wakeup of Task 4 (ready queue length = 1)\n",
    "    14: Run Task 4 for duration 1 (ready queue length = 0)\n",
    "    15: IO wait for Task 4 for duration 1\n",
    "    15: Idle for 1\n",
    "    16: Wakeup of Task 3 (ready queue length = 1)\n",
    "    16: Wakeup of Task 4 (ready queue length = 2)\n",
    "    16: Run Task 3 for duration 1 (ready queue length = 1)\n",
    "    17: Run Task 4 for duration 1 (ready queue length = 0)\n",
    "    18: Stop\n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_fcfs_workload1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_round_robin():\n",
    "    \"\"\" Test round robin on workload1\n",
    "    \n",
    "    >>> _ = round_robin(workload1, 2, True)\n",
    "    0: Arrival of Task 1 (ready queue length = 1)\n",
    "    0: Run Task 1 for duration 2 (ready queue length = 0)\n",
    "    1: Arrival of Task 2 (ready queue length = 1)\n",
    "    2: Arrival of Task 3 (ready queue length = 2)\n",
    "    2: Run Task 2 for duration 2 (ready queue length = 2)\n",
    "    3: Arrival of Task 4 (ready queue length = 3)\n",
    "    4: Run Task 3 for duration 1 (ready queue length = 3)\n",
    "    5: IO wait for Task 3 for duration 4\n",
    "    5: Run Task 1 for duration 2 (ready queue length = 2)\n",
    "    7: Run Task 4 for duration 1 (ready queue length = 1)\n",
    "    8: IO wait for Task 4 for duration 1\n",
    "    8: Run Task 2 for duration 2 (ready queue length = 0)\n",
    "    9: Wakeup of Task 3 (ready queue length = 1)\n",
    "    9: Wakeup of Task 4 (ready queue length = 2)\n",
    "    10: Run Task 3 for duration 1 (ready queue length = 2)\n",
    "    11: Run Task 4 for duration 1 (ready queue length = 1)\n",
    "    12: IO wait for Task 4 for duration 1\n",
    "    12: Run Task 2 for duration 2 (ready queue length = 0)\n",
    "    13: Wakeup of Task 4 (ready queue length = 1)\n",
    "    14: Run Task 4 for duration 1 (ready queue length = 1)\n",
    "    15: Run Task 2 for duration 1 (ready queue length = 0)\n",
    "    16: Stop\n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_round_robin, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Behavior on CPU-only Workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCFS exhibits convoy effect\n",
    "\n",
    "fcfs_cpu = fcfs(workload2, True)\n",
    "analyze(fcfs_cpu.threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round robin services the later arriving short ones, more evenly distributing wait\n",
    "\n",
    "rr40_CPU = round_robin(workload2, 40, True)\n",
    "analyze(rr40_CPU.threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round robin with short quanta causes the interactive jobs to wait\n",
    "\n",
    "rr20_cpu = round_robin(workload2, 20, True)\n",
    "analyze(rr20_cpu.threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Scheduling Simulator Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the implementations of the SRTF and MLFQ schedulers below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortest Remaining Time First\n",
    "\n",
    "Use our oracle knowledge of the future of each job to select the one that will finish soonest.  This inherits from the generic queue providing a specialized dequeue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRTFQueue(FIFOQueue):\n",
    "    \"\"\" Shortest remaining time first queue - with perfect knowledge \"\"\"\n",
    "    def dequeue(self, at_time):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "        \n",
    "def srtf(tasks, q, verbose=False):\n",
    "    return scheduler(tasks, q, SRTFQueue, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_srtf1():\n",
    "    \"\"\" Test SRTF\n",
    "    \n",
    "    >>> _ = srtf(workload1, 2, True)\n",
    "    0: Arrival of Task 1 (ready queue length = 1)\n",
    "    0: Run Task 1 for duration 2 (ready queue length = 0)\n",
    "    1: Arrival of Task 2 (ready queue length = 1)\n",
    "    2: Arrival of Task 3 (ready queue length = 2)\n",
    "    2: Run Task 1 for duration 2 (ready queue length = 2)\n",
    "    3: Arrival of Task 4 (ready queue length = 3)\n",
    "    4: Run Task 3 for duration 1 (ready queue length = 2)\n",
    "    5: IO wait for Task 3 for duration 4\n",
    "    5: Run Task 4 for duration 1 (ready queue length = 1)\n",
    "    6: IO wait for Task 4 for duration 1\n",
    "    6: Run Task 2 for duration 2 (ready queue length = 0)\n",
    "    7: Wakeup of Task 4 (ready queue length = 1)\n",
    "    8: Run Task 4 for duration 1 (ready queue length = 1)\n",
    "    9: Wakeup of Task 3 (ready queue length = 2)\n",
    "    9: IO wait for Task 4 for duration 1\n",
    "    9: Run Task 3 for duration 1 (ready queue length = 1)\n",
    "    10: Wakeup of Task 4 (ready queue length = 2)\n",
    "    10: Run Task 4 for duration 1 (ready queue length = 1)\n",
    "    11: Run Task 2 for duration 2 (ready queue length = 0)\n",
    "    13: Run Task 2 for duration 2 (ready queue length = 0)\n",
    "    15: Run Task 2 for duration 1 (ready queue length = 0)\n",
    "    16: Stop\n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you implemented SRTF correctly, this test should pass\n",
    "test(test_srtf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortest Remaining Time first sets aside the long one and services all the short ones.\n",
    "\n",
    "def test_srtf2():\n",
    "    \"\"\" Test SRTF\n",
    "    \n",
    "    >>> _ = srtf(workload2, 5, True)\n",
    "    0: Idle for 10\n",
    "    10: Arrival of Task 5 (ready queue length = 1)\n",
    "    10: Run Task 5 for duration 5 (ready queue length = 0)\n",
    "    15: Run Task 5 for duration 5 (ready queue length = 0)\n",
    "    20: Arrival of Task 6 (ready queue length = 1)\n",
    "    20: Run Task 5 for duration 5 (ready queue length = 1)\n",
    "    25: Run Task 5 for duration 5 (ready queue length = 1)\n",
    "    30: Arrival of Task 7 (ready queue length = 2)\n",
    "    30: Run Task 5 for duration 5 (ready queue length = 2)\n",
    "    35: Run Task 5 for duration 5 (ready queue length = 2)\n",
    "    40: Arrival of Task 8 (ready queue length = 3)\n",
    "    40: Run Task 8 for duration 5 (ready queue length = 2)\n",
    "    45: Run Task 8 for duration 5 (ready queue length = 2)\n",
    "    50: Run Task 8 for duration 5 (ready queue length = 2)\n",
    "    55: Run Task 8 for duration 5 (ready queue length = 2)\n",
    "    60: Arrival of Task 9 (ready queue length = 3)\n",
    "    60: Run Task 8 for duration 5 (ready queue length = 3)\n",
    "    65: Run Task 8 for duration 5 (ready queue length = 3)\n",
    "    70: Run Task 9 for duration 5 (ready queue length = 2)\n",
    "    75: Run Task 9 for duration 5 (ready queue length = 2)\n",
    "    80: Arrival of Task 10 (ready queue length = 3)\n",
    "    80: Run Task 9 for duration 5 (ready queue length = 3)\n",
    "    85: Run Task 9 for duration 5 (ready queue length = 3)\n",
    "    90: Run Task 9 for duration 5 (ready queue length = 3)\n",
    "    95: Run Task 9 for duration 5 (ready queue length = 3)\n",
    "    100: Arrival of Task 11 (ready queue length = 4)\n",
    "    100: Run Task 11 for duration 5 (ready queue length = 3)\n",
    "    105: Run Task 11 for duration 5 (ready queue length = 3)\n",
    "    110: Run Task 11 for duration 5 (ready queue length = 3)\n",
    "    115: Run Task 11 for duration 5 (ready queue length = 3)\n",
    "    120: Run Task 11 for duration 5 (ready queue length = 3)\n",
    "    125: Run Task 11 for duration 5 (ready queue length = 3)\n",
    "    130: Run Task 10 for duration 5 (ready queue length = 2)\n",
    "    135: Run Task 10 for duration 5 (ready queue length = 2)\n",
    "    140: Run Task 10 for duration 5 (ready queue length = 2)\n",
    "    145: Run Task 10 for duration 5 (ready queue length = 2)\n",
    "    150: Run Task 10 for duration 5 (ready queue length = 2)\n",
    "    155: Run Task 10 for duration 5 (ready queue length = 2)\n",
    "    160: Run Task 6 for duration 5 (ready queue length = 1)\n",
    "    165: Run Task 6 for duration 5 (ready queue length = 1)\n",
    "    170: Run Task 6 for duration 5 (ready queue length = 1)\n",
    "    175: Run Task 6 for duration 5 (ready queue length = 1)\n",
    "    180: Run Task 6 for duration 5 (ready queue length = 1)\n",
    "    185: Run Task 6 for duration 5 (ready queue length = 1)\n",
    "    190: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    195: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    200: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    205: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    210: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    215: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    220: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    225: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    230: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    235: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    240: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    245: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    250: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    255: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    260: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    265: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    270: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    275: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    280: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    285: Run Task 7 for duration 5 (ready queue length = 0)\n",
    "    290: Stop\n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you implemented SRTF correctly, this test should pass\n",
    "test(test_srtf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy-and-paste the output of this cell as your answer to Problem 1(a).\n",
    "_ = srtf(workload3, 2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLFQ with Two Levels\n",
    "\n",
    "A foreground interactive queue with a small quantum and a background CPU-bound queue with a large quantum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLevelFeedbackQueue(object):\n",
    "    \"\"\" Dual Queue of tasks to be scheduled \"\"\"\n",
    "    def __init__(self, q_int, q_cpu):\n",
    "        self.queue = deque()\n",
    "        self.q = q_int\n",
    "        self.q_cpu = q_cpu\n",
    "        self.cpu_queue = deque()\n",
    "    \n",
    "    def enqueue(self, thread, at_time):\n",
    "        \"\"\"Insert into interactive\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "        \n",
    "    def enqueue_cpu(self, thread, at_time):\n",
    "        \"\"\"Insert into non-interactive\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "        \n",
    "    def dequeue(self, at_time):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    def arrive(self, thread, at_time):\n",
    "        self.enqueue(thread, at_time)\n",
    "    \n",
    "    def wake(self, thread, at_time):\n",
    "        self.enqueue(thread, at_time)\n",
    "    \n",
    "    def empty(self):\n",
    "        return not self.queue and not self.cpu_queue\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.queue) + len(self.cpu_queue)\n",
    "    \n",
    "    def weight(self):\n",
    "        return sum([t.remaining() for t in self.queue]) + sum([t.remaining() for t in self.cpu_queue])\n",
    "\n",
    "\n",
    "def mlfq2(tasks, q1, q2, verbose=False):\n",
    "    remaining = TaskStream(tasks)\n",
    "    ready = TwoLevelFeedbackQueue(q1, q2)\n",
    "    cpu = Machine(remaining, ready, verbose)\n",
    "\n",
    "    while not ready.empty() or cpu.next_start():\n",
    "        if ready.empty():\n",
    "            cpu.idle()\n",
    "        else:     \n",
    "            thread, quanta = ready.dequeue(cpu.time)\n",
    "            run_time, status, io_time = thread.run(quanta)\n",
    "            cpu.run(run_time, thread)\n",
    "            \n",
    "            if status == 'io' and io_time > 0:\n",
    "                cpu.io_wait(thread, io_time)\n",
    "            elif status == 'cpu':\n",
    "                ready.enqueue_cpu(thread, cpu.time)\n",
    "            elif status != 'done':                \n",
    "                ready.enqueue(thread, cpu.time)      \n",
    "    cpu.stop()\n",
    "    return cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mlfq21():\n",
    "    \"\"\" Test MLFQ2\n",
    "    \n",
    "    >>> _ = mlfq2(workload1, 2, 4, True)\n",
    "    0: Arrival of Task 1 (ready queue length = 1)\n",
    "    0: Run Task 1 for duration 2 (ready queue length = 0)\n",
    "    1: Arrival of Task 2 (ready queue length = 1)\n",
    "    2: Arrival of Task 3 (ready queue length = 2)\n",
    "    2: Run Task 2 for duration 2 (ready queue length = 2)\n",
    "    3: Arrival of Task 4 (ready queue length = 3)\n",
    "    4: Run Task 3 for duration 1 (ready queue length = 3)\n",
    "    5: IO wait for Task 3 for duration 4\n",
    "    5: Run Task 4 for duration 1 (ready queue length = 2)\n",
    "    6: IO wait for Task 4 for duration 1\n",
    "    6: Run Task 1 for duration 2 (ready queue length = 1)\n",
    "    7: Wakeup of Task 4 (ready queue length = 2)\n",
    "    8: Run Task 4 for duration 1 (ready queue length = 1)\n",
    "    9: Wakeup of Task 3 (ready queue length = 2)\n",
    "    9: IO wait for Task 4 for duration 1\n",
    "    9: Run Task 3 for duration 1 (ready queue length = 1)\n",
    "    10: Wakeup of Task 4 (ready queue length = 2)\n",
    "    10: Run Task 4 for duration 1 (ready queue length = 1)\n",
    "    11: Run Task 2 for duration 4 (ready queue length = 0)\n",
    "    15: Run Task 2 for duration 1 (ready queue length = 0)\n",
    "    16: Stop\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you implemented MLFQ2 correctly, this test should pass\n",
    "test(test_mlfq21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dual queue recognizes the long one after 1st quantum and moves to the long queue\n",
    "# No oracle information is needed.\n",
    "\n",
    "def test_mlfq22():\n",
    "    \"\"\" Test MLFQ2\n",
    "    \n",
    "    >>> _ = mlfq2(workload2, 50, 200, True)\n",
    "    0: Idle for 10\n",
    "    10: Arrival of Task 5 (ready queue length = 1)\n",
    "    10: Run Task 5 for duration 30 (ready queue length = 0)\n",
    "    20: Arrival of Task 6 (ready queue length = 1)\n",
    "    30: Arrival of Task 7 (ready queue length = 2)\n",
    "    40: Arrival of Task 8 (ready queue length = 3)\n",
    "    40: Run Task 6 for duration 30 (ready queue length = 2)\n",
    "    60: Arrival of Task 9 (ready queue length = 3)\n",
    "    70: Run Task 7 for duration 50 (ready queue length = 2)\n",
    "    80: Arrival of Task 10 (ready queue length = 3)\n",
    "    100: Arrival of Task 11 (ready queue length = 4)\n",
    "    120: Run Task 8 for duration 30 (ready queue length = 4)\n",
    "    150: Run Task 9 for duration 30 (ready queue length = 3)\n",
    "    180: Run Task 10 for duration 30 (ready queue length = 2)\n",
    "    210: Run Task 11 for duration 30 (ready queue length = 1)\n",
    "    240: Run Task 7 for duration 50 (ready queue length = 0)\n",
    "    290: Stop\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you implemented MLFQ2 correctly, this test should pass\n",
    "test(test_mlfq22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy-and-paste the output of this cell as your answer to Problem 1(b).\n",
    "_ = mlfq2(workload3, 2, 4, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Approaching 100% Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_exp_arrivals(arrival_rate, service_time, n):\n",
    "    \"\"\"Make n tasks of exponential distributed arrival intervals and lengths\"\"\"\n",
    "    arrivals = np.cumsum(np.random.exponential(1 / arrival_rate, n))\n",
    "    lengths = [service_time for _ in range(n)]\n",
    "    return [Task(arr, run, indefinite, nowait) for arr, run in zip(arrivals, lengths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions may (or may not) be useful for you to implement\n",
    "\n",
    "def cpuUtilization(cpulog):\n",
    "    # Given the Machine's log (list of tuples), computes the average CPU utilization\n",
    "    # YOUR CODE HERE\n",
    "    return 0\n",
    "\n",
    "def responseTimes(cpulog):\n",
    "    # Given the Machine's log, computes the response time of each task, and returns a list containing them\n",
    "    # YOUR CODE HERE\n",
    "    return [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l and lmbdas are \"recommended values\" that you can change if desired\n",
    "l = 10\n",
    "lmbdas = np.array((0.2, 0.5, 0.7, 0.8, 0.9, 0.93, 0.95, 0.97, 0.99)) / l\n",
    "\n",
    "# Decrease this when developing in case it takes too long\n",
    "TRIALS = 100\n",
    "\n",
    "response_time_medians = []\n",
    "response_time_95th_percentiles = []\n",
    "utilizations = []\n",
    "for lmbda in lmbdas:\n",
    "    trial_utilizations = []\n",
    "    trial_medians = []\n",
    "    trial_95ths = []\n",
    "    \n",
    "    for _ in range(TRIALS):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    response_time_medians.append(np.mean(trial_medians))\n",
    "    response_time_95th_percentiles.append(np.mean(trial_95ths))\n",
    "    utilizations.append(np.mean(trial_utilizations))\n",
    "    \n",
    "    # This takes a while to run so this print statement lets us track progress\n",
    "    print(\"Finished\", lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Arrival Rate (lambda)\")\n",
    "plt.ylabel(\"Utilization\")\n",
    "plt.plot(lmbdas, utilizations)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Arrival Rate ($\\lambda$)\")\n",
    "plt.ylabel(\"Response Time\")\n",
    "plt.plot(lmbdas, response_time_95th_percentiles, label=\"95th percentile\")\n",
    "plt.plot(lmbdas, response_time_medians, label=\"median\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Fairness for CPU Bursts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)\n",
    "\n",
    "\n",
    "\n",
    "با توجه به اینکه هر پردازه، تا زمانی که تسک فعلی‌اش تمام نشده تسک بعدی را شروع نمی‌کند پس هر پردازه حداکثر یک تسک می‌تواند در صف داشته باشد در نتیجه طول صف حداکثر ۲ خواهد بود."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)\n",
    "\n",
    "۱/۲\n",
    "\n",
    "چون توزیع این متغیر های تصادفی با یکدیگر برابر است پس احتمال اینکه \n",
    "\n",
    "s\n",
    "\n",
    "از\n",
    "\n",
    "t\n",
    "\n",
    "بزرگتر باشد برابر است با احتمال اینکه \n",
    "\n",
    "t\n",
    "\n",
    "از \n",
    "\n",
    "s\n",
    "\n",
    "بزرگتر باشد پس پاسخ ۰.۵ است."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)\n",
    "\n",
    "due to the CLT we have: \n",
    "$$N(0,1) \\approx \\sqrt{m}\\frac{\\bar{S}-E[S]}{\\sqrt{var(S)}} $$\n",
    "$$N(0,\\frac{1}{m}) \\approx \\frac{\\bar{S}-E[S]}{\\sqrt{var(S)}} $$\n",
    "$$N(0,\\frac{var(S)}{m}) \\approx \\bar{S}-E[S] $$\n",
    "$$N(E[S],\\frac{var(S)}{m}) \\approx \\bar{S} $$\n",
    "$$N(E[S]*m,var(S)*m ) \\approx \\text{total time} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)\n",
    "\n",
    "at first note that distributions of S and T are their relative CPU time are the same and is shown above. now let's see the lemma below:\n",
    "\n",
    "### Lemma:\n",
    "\n",
    "\n",
    "Suppose that $X_1 \\sim {\\rm N}(\\mu_1,\\sigma_1^2)$ and $X_2 \\sim {\\rm N}(\\mu_2,\\sigma_2^2)$ are independent. Then,\n",
    "$$\n",
    "{\\rm P}(X_1  \\gt; X_2 ) = {\\rm P}(X_1  - X_2  \\gt; 0) = 1 - {\\rm P}(X_1  - X_2  \\le 0).\n",
    "$$\n",
    "Now, by independence, $X_1 - X_2$ is normally distributed with mean\n",
    "$$\n",
    "\\mu := {\\rm E}(X_1 - X_2) = \\mu_1 - \\mu_2\n",
    "$$\n",
    "and variance\n",
    "$$\n",
    "\\sigma^2 := {\\rm Var}(X_1 - X_2) = \\sigma_1^2 + \\sigma_2^2.\n",
    "$$\n",
    "Hence, \n",
    "$$\n",
    "\\frac{{X_1  - X_2  - \\mu}}{{\\sigma}} \\sim {\\rm N}(0,1),\n",
    "$$\n",
    "and so\n",
    "$$\n",
    "{\\rm P}(X_1  - X_2  \\le 0) = {\\rm P}\\bigg(\\frac{{X_1  - X_2  - \\mu }}{\\sigma } \\le \\frac{{0 - \\mu }}{\\sigma }\\bigg) = \\Phi \\Big(  \\frac{-\\mu }{\\sigma }\\Big),\n",
    "$$\n",
    "where $\\Phi$ is the distribution function of the ${\\rm N}(0,1)$ distribution. Thus,\n",
    "\n",
    "$${\\rm P}(X_1  \\gt; X_2 )  = 1 - {\\rm P}(X_1  - X_2  \\le 0) = 1 - \\Phi \\Big(  \\frac{-\\mu }{\\sigma }\\Big).$$\n",
    "\n",
    "---\n",
    "in our case $\\mu$ is $(1-\\alpha)\\times E[S]\\times m$. and $\\sigma^2$ is $(1+\\alpha^2)\\times var(S)\\times m$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5)\n",
    "\n",
    "let's subtitute the assumption in the above relation:\n",
    "\n",
    "$$1-\\Phi(\\frac{(\\alpha-1)\\sqrt{var(S)}\\times m}{\\sqrt{(1+\\alpha^2)var(S)\\times m}})$$\n",
    "$$ = 1-\\Phi(\\frac{(\\alpha-1)\\times \\sqrt{m}}{\\sqrt{(1+\\alpha^2)}})$$\n",
    "\n",
    "now we set $\\alpha = 1.1$. Also note that the final solution will be twice of the above probability, since either of processes can preceed other one.\n",
    "\n",
    "---\n",
    "for $m=100$ we have:\n",
    "\n",
    "$$ 2 \\times (1 - \\Phi(0.6726728)) = 0.5012 $$\n",
    "\n",
    "---\n",
    "for $m= 10, 000$ we have:\n",
    "$$ 2\\times(1 - \\Phi(6.726728) ) = 17152 * 10^{-12} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "therefore, behnam idea about fairness of the algorithm does not hold for lower `m`s. and as `m` get larger the algotithm become more fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "def create_problem3_task(lmbda, num_bursts):\n",
    "    run_time = np.random.normal(num_bursts/lmbda, np.sqrt(num_bursts)/lmbda)\n",
    "    return Task(0, run_time, make_exponential(lmbda), nowait)\n",
    "\n",
    "    \n",
    "\n",
    "def create_problem3_workload(lmbda, num_bursts):\n",
    "    task_S = create_problem3_task(lmbda, num_bursts)\n",
    "    task_T = create_problem3_task(lmbda, num_bursts)\n",
    "    return task_S, task_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of runs that were unfair: 0.836\n",
      "Fraction of runs that were unfair: 0.746\n",
      "Fraction of runs that were unfair: 0.669\n",
      "Fraction of runs that were unfair: 0.589\n",
      "Fraction of runs that were unfair: 0.5038\n",
      "Fraction of runs that were unfair: 0.42933333333333334\n",
      "Fraction of runs that were unfair: 0.36828571428571427\n",
      "Fraction of runs that were unfair: 0.32225\n",
      "Fraction of runs that were unfair: 0.28644444444444445\n"
     ]
    }
   ],
   "source": [
    "# Feel free to change this while developing if it takes too long to run\n",
    "TRIALS = 1000\n",
    "N = 1.1\n",
    "\n",
    "unfair_count = 0\n",
    "fair_count = 0\n",
    "m = [10, 50, 100, 200, 400, 800, 2000, 4000, 10000]\n",
    "fairness = []\n",
    "for x in m:\n",
    "    for _ in range(TRIALS):\n",
    "        fcfs_cpu = fcfs(create_problem3_workload(22220.0, x), False)\n",
    "        elapsed_0 = fcfs_cpu.threads[0].elapsed_time\n",
    "        elapsed_1 = fcfs_cpu.threads[1].elapsed_time\n",
    "    #     print(elapsed_0, elapsed_1)\n",
    "        if elapsed_0 / elapsed_1 > N or elapsed_1 / elapsed_0 > N:\n",
    "            unfair_count += 1\n",
    "        else:\n",
    "            fair_count += 1\n",
    "    tmp = unfair_count / (fair_count + unfair_count)\n",
    "    fairness.append(tmp)\n",
    "    print(\"Fraction of runs that were unfair:\", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(m, fairness)\n",
    "plt.xlabel('m')\n",
    "plt.ylabel('fairness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we take a list of possible values of `m`. Then for each value we start simulating by using the function of `create_problem3_worklaod` which returns 2 tasks that their total run time distribution are calculated by formula in part 3.\n",
    "As we can see in the above figure, as m grows, the fairness will decreases which confirms the results of previous part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Interesting Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some other interesting types of graphs you can make, that might be useful to you as you complete the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions to process the logs\n",
    "\n",
    "def showQlen(cpulog):\n",
    "    times = [x[0] for x in cpulog if x[1] == 'run']\n",
    "    lengths = [x[4] for x in cpulog if x[1] == 'run']\n",
    "    plt.plot(np.repeat(times,2)[1:], np.repeat(lengths,2)[0:-1])\n",
    "    \n",
    "def showQweight(cpulog):\n",
    "    times = [x[0] for x in cpulog if x[1] == 'run']\n",
    "    weights = [x[5] for x in cpulog if x[1] == 'run']\n",
    "    plt.plot(np.repeat(times,2)[1:], np.repeat(weights,2)[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tasks with exponentially distributed arrival times and run lengths\n",
    "# The utilization is essentially the ratio of the means, but be careful as it gets loaded.\n",
    "utilization = 0.9\n",
    "interval = 40\n",
    "run_length = interval*utilization\n",
    "etasks = make_exp_arrivals(1 / interval, run_length, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecpu_fcfs = fcfs(etasks)\n",
    "wait_fcfs = sum([x.wait_time for x in ecpu_fcfs.threads])\n",
    "ecpu_rr = round_robin(etasks, 5)\n",
    "wait_rr = sum([x.wait_time for x in ecpu_rr.threads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_fcfs, wait_rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showQlen(ecpu_fcfs.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showQlen(ecpu_rr.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showQweight(ecpu_fcfs.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showQweight(ecpu_rr.log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
